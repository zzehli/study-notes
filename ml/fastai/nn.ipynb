{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e701aa",
   "metadata": {},
   "source": [
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92373117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "\n",
    "def matmul(a, b):\n",
    "    ar, ac = a.shape  # n_rows * n_cols\n",
    "    br, bc = b.shape\n",
    "    assert ac == br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac):\n",
    "                c[i, j] += a[i, k] * b[k, j]\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d343c4",
   "metadata": {},
   "source": [
    "Say we are working with 5 MNIST images each of size (28 by 28), we turn them into 10 activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6875389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.6165, -10.1676,  21.6245,  -2.6803, -64.2527, -28.5411, -10.5376,\n",
       "          36.7678,  -4.2712,   8.9385],\n",
       "        [ 26.7987,   7.4983, -40.0363, -14.0619,  11.2322, -11.8173,  20.1772,\n",
       "          -8.1895,  15.2847,   7.0598],\n",
       "        [  0.8149,   9.0984,  27.9498, -15.3219, -13.3059,   7.1128, -18.9964,\n",
       "         -29.5449, -29.8525,   6.2420],\n",
       "        [-30.5308,   9.2034,  14.0495, -24.3064, -30.7182,  23.1877,  17.8508,\n",
       "          43.2565, -27.7722,  -5.1529],\n",
       "        [  3.4262,   0.3862, -39.1668, -54.1615,   3.0668, -44.7902,  -5.7787,\n",
       "          18.5482,  30.4846,  -6.3429]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.randn(5, 28 * 28)\n",
    "m2 = torch.randn(28 * 28, 10)\n",
    "matmul(m1, m2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008eb75",
   "metadata": {},
   "source": [
    "However, this is slow. We will move this implementation to Pytorch, Basic operation with two tensors are applied elementwise in Pytorch.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6169490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12., 14.,  3.]), tensor([False,  True,  True]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10.0, 6, -4])\n",
    "b = tensor([2.0, 8, 7])\n",
    "a + b, a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab9e827",
   "metadata": {},
   "source": [
    "We will replace the inner loop with it's PyTorch equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b307448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    ar, ac = a.shape\n",
    "    br, bc = b.shape\n",
    "    assert ac == br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            c[i, j] = (a[i] * b[:, j]).sum()\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb409d1b",
   "metadata": {},
   "source": [
    "We will further leverage broadcasting to improve this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34733ec",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "Broadcasting works by comparing corresponding dimensions of two vectors/scalars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf317ec",
   "metadata": {},
   "source": [
    "We can broadcast a scalar to a vector/matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e85614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10.0, 6, -4])\n",
    "a > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67eafc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4652, -1.0989, -0.7326],\n",
       "        [-0.3663,  0.0000,  0.3663],\n",
       "        [ 0.7326,  1.0989,  1.4652]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1.0, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "(m - 5) / 2.73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93156924",
   "metadata": {},
   "source": [
    "We can also broadcast a vector to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d22c03be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]),\n",
       " torch.Size([3]),\n",
       " tensor([[11., 22., 33.],\n",
       "         [14., 25., 36.],\n",
       "         [17., 28., 39.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.0, 20, 30])\n",
    "m = tensor([[1.0, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "m.shape, c.shape, m + c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffca5ae",
   "metadata": {},
   "source": [
    "Under the hood, the vector is stretched by calling the `expand_as` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "913d9f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.expand_as(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598ea81",
   "metadata": {},
   "source": [
    "We can look at how it is stored by calling the `storage` method. Notice that the result of a vector-turned-matrix is not stored as a 3 x 3 (2-d) matrix, but still a 1-d vector.\n",
    "\n",
    "This is because the vector has a stride of 0, which means when Pytorch goes to the next row by adding the stride, the row doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1726e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "( 10.0\n",
       "  20.0\n",
       "  30.0\n",
       " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 3],\n",
       " (0, 1),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = c.expand_as(m)\n",
    "t.storage(), t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e66825",
   "metadata": {},
   "source": [
    "When the # of dimensions are not compatible, Pytorch calls `unsqueeze` method first to add a size 1 dimension. By default, the new dimension is added at the beginning (`unsqueeze(0)`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "781c9f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]), torch.Size([3, 1]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.0, 20, 30])\n",
    "m = tensor([[1.0, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "c_1 = c.unsqueeze(1)\n",
    "c_0 = c.unsqueeze(0)  # what Pytorch does\n",
    "m.shape, c.shape, c_1.shape, c_0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9ffa7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10., 20., 30.]]),\n",
       " tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_0, c_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccaabef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[11., 22., 33.],\n",
       "         [14., 25., 36.],\n",
       "         [17., 28., 39.]]),\n",
       " tensor([[11., 12., 13.],\n",
       "         [24., 25., 26.],\n",
       "         [37., 38., 39.]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_0 + m, c_1 + m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221bb7a",
   "metadata": {},
   "source": [
    "We can now use broadcasting in `matmul`, which accelerate the function further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "699ce41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    ar, ac = a.shape\n",
    "    br, bc = b.shape\n",
    "    assert ac == br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        # c[i,j] = (a[i,:] * b[:,j]).sum() # previous\n",
    "        c[i] = (a[i].unsqueeze(-1) * b).sum(dim=0)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca16cdf",
   "metadata": {},
   "source": [
    "# Forward pass\n",
    "\n",
    "The forward pass is the process of use input and the model to calculate output (based on matrix multiplication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "102c4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b):\n",
    "    return x @ w + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03154d22",
   "metadata": {},
   "source": [
    "To define a nn, we put two linear layers together, with a nonlinear function, the activation function, in the middle (since the composition of two linear function is just one linear function, which doesn't amounts to 2 layers).\n",
    "\n",
    "We initialize the weight for a linear layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1063f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(200, 100)\n",
    "y = torch.randn(200)\n",
    "\n",
    "\n",
    "w1 = torch.randn(100, 50)\n",
    "b1 = torch.zeros(50)\n",
    "w2 = torch.randn(50, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb58253",
   "metadata": {},
   "source": [
    "A problem with this set of weights is that the output of the model after several layers because very big. That is because after going through several linear transformations, matrix multiplications will lead to a very large number. This can be illustrated by iteratively perform matrix multiplications on a matrix. As we can see, the weight matrix becomes very big quickly. This won't work for deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f03dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(200, 100)\n",
    "for i in range(50):\n",
    "    x = x @ torch.randn(100, 100)\n",
    "x[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840db1a",
   "metadata": {},
   "source": [
    "Kaiming He et al. introduced the right scaling factor for neural net with relu in their ResNet paper, which is $\\sqrt{2/n_{in}}$, where $n_{in}$ is the number of input. So we initialize according to this approach instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e01e5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x = torch.randn(200, 100)\n",
    "y = torch.randn(200)\n",
    "\n",
    "w1 = torch.randn(100, 50) * math.sqrt(2 / 100)\n",
    "b1 = torch.zeros(50)\n",
    "w2 = torch.randn(50, 1) * math.sqrt(2 / 50)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a5cb3",
   "metadata": {},
   "source": [
    "We define an activation function, the nonlinear function, with **relu**, which clamps a tensor at 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b02dbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155ac91",
   "metadata": {},
   "source": [
    "Now we can calculate how an input goes thru the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "088d6f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5728), tensor(0.8428))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = lin(x, w1, b1)\n",
    "l2 = relu(l1)\n",
    "l2.mean(), l2.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685f4d5",
   "metadata": {},
   "source": [
    "And we can define our neural network as, which is also our forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ea41b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    l1 = lin(x, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d17e0",
   "metadata": {},
   "source": [
    "# Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2142e42",
   "metadata": {},
   "source": [
    "The backward pass calculates a loss function, which compute a measure of difference between the output of the forward pass and our label (`y` in our case). In our case, we use mean squared error.\n",
    "\n",
    "However, we have 1 minor problem. Our model should have an output of shape `[200]` (the shape of `y`), but right now it has a trailing 1 dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39abf426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5cf26",
   "metadata": {},
   "source": [
    "We get rid of the training 1 with `squeeze` method in our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b42262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ):\n",
    "    return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ce804",
   "metadata": {},
   "source": [
    "Now we need to calculate gradients wrt our loss function, the mean root square. To do so, we apply chain rule. To implement the chain rule for all operations we have, we save gradient of every function we have wrt the inputs.\n",
    "\n",
    "For mean squared error, the gradient wrt to the input (which is the output of the forward pass) is\n",
    "$$\n",
    "\\frac{d}{d \\text{output}}mse(\\text{output}, \\text{targ}) = 2(\\text{output} - \\text{targ}) * 1/n\n",
    "$$\n",
    "where $n$ is the # of elem in $output$\n",
    "\n",
    "For relu, the gradient wrt to the input is 1 or 0 depending on the input. Because, the result of relu is not final, we need to apply chain rule, which mean we need to time the result with the gradient of the next step, `out.g`:\n",
    "$$\n",
    "g = g_{relu} \\cdot g_{out}\n",
    "$$\n",
    "where $g_{relu}$ is:\n",
    "$$\n",
    "\\frac{d}{d \\text{input}}relu(\\text{input}) = \n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Similarly, for the linear function we have\n",
    "$$\n",
    "g = g_{lin} \\cdot g_{out}\n",
    "$$\n",
    "where $g_{lin}$ is:\n",
    "$$\n",
    "\\frac{d}{d \\text{input}}lin(\\text{input}) = w\n",
    "$$\n",
    "\n",
    "This gives use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e51c1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    # grad of loss with respect to output of previous layer\n",
    "    inp.g = 2.0 * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]\n",
    "\n",
    "\n",
    "def relu_grad(inp, out):\n",
    "    # grad of relu with respect to input activations\n",
    "    inp.g = (inp > 0).float() * out.g\n",
    "\n",
    "\n",
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul with respect to input\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = inp.t() @ out.g\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c33402",
   "metadata": {},
   "source": [
    "The backward pass is simply run these gradient one at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2db187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w2 + b2\n",
    "\n",
    "    # backward pass:\n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f52370",
   "metadata": {},
   "source": [
    "# Refactor to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd0d94",
   "metadata": {},
   "source": [
    "Next, we want to move the current implementation into pytorch. To do that, we first organize the code into classes where each operation has a forward pass and a backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f634c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.0)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = (self.inp > 0).float() * self.out.g\n",
    "\n",
    "\n",
    "class Lin:\n",
    "    def __init__(self, w, b):\n",
    "        self.w, self.b = w, b\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = self.inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "\n",
    "\n",
    "class Mse:\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        x = (self.inp.squeeze() - self.targ).unsqueeze(-1)\n",
    "        self.inp.g = 2.0 * x / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6291c6",
   "metadata": {},
   "source": [
    "We will also create a model class to tie everything together.\n",
    "\n",
    "Here there is something really subtle. Because python is pass by reference, the object relation established in the forward pass gets retained in the backward pass. This make it possible to call `self.out.g` without setting it explicitly.\n",
    "\n",
    "For the forward pass we have:\n",
    "```\n",
    "y1  = lin1(x0)      # lin1.out is y1\n",
    "r1  = relu(y1)      # relu.out is r1; note: r1 is also lin2.inp\n",
    "yhat = lin2(r1)     # lin2.out is yhat; note: yhat is also loss.inp\n",
    "L = loss(yhat, targ)\n",
    "```\n",
    "In the backward pass:\n",
    "```\n",
    "loss.backward() # loss.inp.g is now set → therefore lin2.out.g is set\n",
    "lin2.backward() # lin2 reads its out.g (set by loss), writes its inp.g (which is relu.out.g)\n",
    "relu.backward() # relu reads its out.g (set by lin2), writes its inp.g (which is lin1.out.g)\n",
    "lin1.backward() # lin1 reads its out.g (set by relu), writes its inp.g (which is x0.g)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e4421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "\n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "\n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940fe1e",
   "metadata": {},
   "source": [
    "Now we are in a position to perform forward and backward pass similar to how pytorch does it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f5d0164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 50])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(w1, b1, w2, b2)\n",
    "loss = model(x, y)\n",
    "model.backward()\n",
    "w1.g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728aa034",
   "metadata": {},
   "source": [
    "In Pytorch, we rewrite layers of neural net as child class of `nn.Module`, which is the base structure for Pytorch models. It registers trainable parameters and keeps track of gradients. We derive the equivalent gradient of the layer 1 weight `w1` (note that PyTorch weights' shape, `(out_features, in_features)` is the reverse of how we defined it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4925447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 100]) torch.Size([200])\n",
      "torch.Size([50, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, n_out)\n",
    "        )\n",
    "        self.loss = mse\n",
    "\n",
    "    def forward(self, x, targ):\n",
    "        return self.loss(self.layers(x).squeeze(), targ)\n",
    "\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "model = Model2(100, 50, 1)\n",
    "loss = model(x, y)\n",
    "loss.backward()\n",
    "print(model.layers[0].weight.grad.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
