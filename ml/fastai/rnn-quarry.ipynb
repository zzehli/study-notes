{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3eb723",
   "metadata": {},
   "source": [
    "Recurrent Neural Net (RNN) uses recursion as a strategy to create deep neural nets. By incorporating recursion, it allow nn to retain more information, giving them \"memory\" of longer sequences of information. RNNs use the same hidden weight matrix for all additional layers, which make it memory efficient. It trains this weight matrix by recursively incorporating the next token in the training sequence (like a sentence). RNN is best suited for sequential data like natural language or time series.\n",
    "\n",
    "Suppose the hidden layer is $W$, $e$ are token embeddings, and $h_o$ is the output layer:\n",
    "\n",
    "The first hidden state/activation is $$h_0 = \\text{ReLU}\\big(W\\,e_0 + b\\big)$$\n",
    "The second hidden state is $$h_1 = \\text{ReLU}\\big(W\\,(h_0 + e_1) + b\\big)$$\n",
    "The third hidden state: $$h_2 = \\text{ReLU}\\big(W\\,(h_1 + e_2) + b\\big)$$\n",
    "The output predictions: $$\\text{logits} = h_o(h_2)$$\n",
    "Notice that throughout this process, the hidden layer, $W$, stays the same in the forward pass.\n",
    "\n",
    "In general, the standard RNN is formulated as\n",
    "$$\n",
    "h_t = f(W h_{t-1} + U e_t + b)\n",
    "$$\n",
    "\n",
    "* $h_{t-1}$ : previous hidden state\n",
    "* $e_t$ : embedding (input at this step)\n",
    "* $W$ : hidden-to-hidden weights (processes the past)\n",
    "* $U$ : input-to-hidden weights (processes the current token)\n",
    "* $b$ : bias\n",
    "* $f$ :the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271919be",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e86c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz\" -O \"../data/human_numbers.tgz\" && tar -xzf \"../data/human_numbers.tgz\" -C ../data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ab888ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70aa059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../data/human_numbers/train.txt'), PosixPath('../data/human_numbers/valid.txt')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sample_path = Path(\"../data/human_numbers\")\n",
    "print(list(sample_path.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae013b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open(sample_path / \"train.txt\") as f:\n",
    "    lines += [*f.readlines()]\n",
    "with open(sample_path / \"valid.txt\") as f:\n",
    "    lines += [*f.readlines()]\n",
    "len(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35aab2",
   "metadata": {},
   "source": [
    "Our dataset consists of words of numbers and periods. We calculate the vocab size of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa79a27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.'],\n",
       " 30,\n",
       " ['fifty',\n",
       "  'eleven',\n",
       "  'ninety',\n",
       "  'five',\n",
       "  'four',\n",
       "  'eighteen',\n",
       "  'sixty',\n",
       "  'forty',\n",
       "  'one',\n",
       "  'seven'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" . \".join([l.strip() for l in lines])\n",
    "tokens = text.split(\" \")\n",
    "vocab = set(tokens)\n",
    "tokens[:10], len(vocab), list(vocab)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea67ab2",
   "metadata": {},
   "source": [
    "We convert tokens into index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c73fe950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63095"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "nums = [word2idx[i] for i in tokens]\n",
    "len(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8220417",
   "metadata": {},
   "source": [
    "We will predict every word given the previous words. Todo so, we define the sequence length as `sl`, each element in `seqs` now contains 2 element, offset by 1 index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7976ab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 8, 20, 28, 20, 19, 20,  4, 20,  3, 20, 18, 20,  9, 20, 25, 20]),\n",
       "  tensor([20, 28, 20, 19, 20,  4, 20,  3, 20, 18, 20,  9, 20, 25, 20, 10])),\n",
       " (tensor([10, 20, 22, 20,  1, 20, 11, 20, 29, 20, 21, 20, 13, 20, 16, 20]),\n",
       "  tensor([20, 22, 20,  1, 20, 11, 20, 29, 20, 21, 20, 13, 20, 16, 20, 15])),\n",
       " (tensor([15, 20,  5, 20, 24, 20, 12, 20, 12,  8, 20, 12, 28, 20, 12, 19]),\n",
       "  tensor([20,  5, 20, 24, 20, 12, 20, 12,  8, 20, 12, 28, 20, 12, 19, 20])),\n",
       " (tensor([20, 12,  4, 20, 12,  3, 20, 12, 18, 20, 12,  9, 20, 12, 25, 20]),\n",
       "  tensor([12,  4, 20, 12,  3, 20, 12, 18, 20, 12,  9, 20, 12, 25, 20, 12])),\n",
       " (tensor([12, 10, 20, 14, 20, 14,  8, 20, 14, 28, 20, 14, 19, 20, 14,  4]),\n",
       "  tensor([10, 20, 14, 20, 14,  8, 20, 14, 28, 20, 14, 19, 20, 14,  4, 20]))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl = 16\n",
    "seqs = [\n",
    "    (torch.tensor(nums[i : i + sl]), torch.tensor(nums[i + 1 : i + sl + 1]))\n",
    "    for i in range(0, len(nums) - sl - 1, sl)\n",
    "]\n",
    "cut = int(len(seqs) * 0.8)\n",
    "seqs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e4397",
   "metadata": {},
   "source": [
    "We also need a `DataLoader` to generate continuous sequences across batch in order so that the model can accumulate activations across batches. That's to say, if we have batch size `bs`, our dataset is divided into `m = len(dset) // bs` groups (the # of batches). Across these groups, sequence at index `i` should follow one another. That is to say, ith sequence in every batch should follow one other.\n",
    "\n",
    "For example, our sequences are defined for every 3 words:\n",
    "```\n",
    "[(tensor([2, 6, 5]), 6), (tensor([ 6, 16,  6]), 27), (tensor([27,  6, 29]), 6)]\n",
    "```\n",
    "Our batches should be structured to connect this sequence across batch (notice the 1st elem of each batch come from the sequence). In this case, we have 3 batches each of size 3:\n",
    "```\n",
    "(tensor([[ 2,  6,  5],\n",
    "         [ 8, 14,  4],\n",
    "         [29,  8, 27]]),\n",
    " tensor([[ 6, 16,  6],\n",
    "         [25, 29,  6],\n",
    "         [ 4, 25,  5]]),\n",
    " tensor([[27,  6, 29],\n",
    "         [ 5,  8, 14],\n",
    "         [ 6, 29,  8]]))\n",
    "```\n",
    "\n",
    "We define `group_chunks` to load our dataset based on the logic above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22f49a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_chunks(ds, bs):\n",
    "    m = len(ds) // bs\n",
    "    new_ds = []\n",
    "    for i in range(m):\n",
    "        new_ds += [ds[i + m * j] for j in range(bs)]\n",
    "    return new_ds\n",
    "\n",
    "bs = 64\n",
    "dls_train = DataLoader(group_chunks(seqs[:cut], bs), batch_size=bs, drop_last=True)\n",
    "dls_valid = DataLoader(group_chunks(seqs[cut:], bs), batch_size=bs, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ba651a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 16]), torch.Size([64, 16]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dls_train))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8016f1",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb35b27",
   "metadata": {},
   "source": [
    "We define a classic RNN below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f4919b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel4(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden, bs):\n",
    "        super().__init__()\n",
    "        # input layer\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        # hidden layer\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        # output layer\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        # store dimensions for proper initialization\n",
    "        self.n_hidden = n_hidden\n",
    "        # initiate hidden state properly\n",
    "        self.h = torch.zeros(bs, n_hidden)\n",
    "        # self.h = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, sl = x.shape\n",
    "\n",
    "        out = []\n",
    "        for i in range(sl):\n",
    "            # Add embedding to hidden state\n",
    "            self.h = self.h + self.i_h(x[:, i])\n",
    "            # Apply hidden layer with activation\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "            # Generate output for this timestep\n",
    "            out.append(self.h_o(self.h))\n",
    "        \n",
    "        # Detach hidden state to prevent gradient explosion\n",
    "        self.h = self.h.detach()\n",
    "        return torch.stack(out, dim=1)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the hidden state\"\"\"\n",
    "        self.h = torch.zeros(bs, self.n_hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482c7c2",
   "metadata": {},
   "source": [
    "The output shape of the model is `bs x sl x vocab_sz`, our valid data are `bs x sl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6766493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 16, 30]), torch.Size([64, 16]), torch.Size([64, 16]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dls_train))\n",
    "rnn2 = LMModel4(len(vocab), 64, bs)\n",
    "rnn2(xb).shape, xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5030a",
   "metadata": {},
   "source": [
    "Our loss function need to be modified to align the dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb752662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 30]) torch.Size([1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.4497, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rnn2(xb).view(-1, len(vocab)).shape, yb.view(-1).shape)\n",
    "F.cross_entropy(rnn2(xb).view(-1, len(vocab)), yb.view(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acdbc9",
   "metadata": {},
   "source": [
    "Based on the above, we define our loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a7e3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(inp, targ):\n",
    "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36271849",
   "metadata": {},
   "source": [
    "We also define batch accuracy for our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c674faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(pred, target):\n",
    "    # pred: (bs, sl, vocab), targ: (bs, sl)\n",
    "    return (pred.argmax(-1) == target).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c3309f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 49\n",
      "Validation batches: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training batches: {len(dls_train)}\")\n",
    "print(f\"Validation batches: {len(dls_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41673ea",
   "metadata": {},
   "source": [
    "We will write a standard training loop.\n",
    "\n",
    "Notice that we reset the hidden state of the model at the beginning of each train and validation phases of an epoch by calling the `reset` method defined in the model. this will make sure we start with a clean state before reading those continuous chunks of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e3299ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "# Use a lower learning rate to start\n",
    "rnn2 = LMModel4(len(vocab), 64, bs)\n",
    "\n",
    "optimizer = torch.optim.SGD(rnn2.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=0.01, steps_per_epoch=len(dls_train), epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True  # good if input sizes are consistent\n",
    "def train(model, epochs, train_loader, valid_loader):\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = torch.zeros(())\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        model.reset() # reset hidden state at the beginning of each epoch\n",
    "        for xb, yb in train_loader:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_loss += loss.item()\n",
    "            batch_num += 1  # number of batches within a epoch\n",
    "        avg_loss = epoch_loss / batch_num\n",
    "        model.eval()\n",
    "        model.reset()\n",
    "        with torch.no_grad():\n",
    "            batch_num_valid = 0\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            for xb, yb in valid_loader:\n",
    "                pred = model(xb)\n",
    "                valid_loss += loss_func(pred, yb).item()\n",
    "                valid_acc += batch_accuracy(pred, yb)\n",
    "                batch_num_valid += 1\n",
    "        print(f\"epoch {epoch}, train loss: {avg_loss:.4f}\")\n",
    "        print(f\"validation loss {valid_loss / batch_num_valid:.4f}\")\n",
    "        print(f\"validation accuracy {valid_acc / batch_num_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3fd07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 3.3648\n",
      "validation loss 3.2658\n",
      "validation accuracy 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 2.8509\n",
      "validation loss 2.6469\n",
      "validation accuracy 0.2459\n",
      "epoch 2, train loss: 2.0083\n",
      "validation loss 2.0225\n",
      "validation accuracy 0.4651\n",
      "epoch 3, train loss: 1.5979\n",
      "validation loss 1.9134\n",
      "validation accuracy 0.4695\n",
      "epoch 4, train loss: 1.5244\n",
      "validation loss 1.8921\n",
      "validation accuracy 0.4628\n",
      "epoch 5, train loss: 1.4827\n",
      "validation loss 1.8661\n",
      "validation accuracy 0.4596\n",
      "epoch 6, train loss: 1.4420\n",
      "validation loss 1.8273\n",
      "validation accuracy 0.4598\n",
      "epoch 7, train loss: 1.4049\n",
      "validation loss 1.8006\n",
      "validation accuracy 0.4674\n",
      "epoch 8, train loss: 1.3770\n",
      "validation loss 1.7890\n",
      "validation accuracy 0.4733\n",
      "epoch 9, train loss: 1.3497\n",
      "validation loss 1.7694\n",
      "validation accuracy 0.4794\n",
      "epoch 10, train loss: 1.3219\n",
      "validation loss 1.7587\n",
      "validation accuracy 0.4907\n",
      "epoch 11, train loss: 1.2936\n",
      "validation loss 1.7449\n",
      "validation accuracy 0.5023\n",
      "epoch 12, train loss: 1.2624\n",
      "validation loss 1.7234\n",
      "validation accuracy 0.5144\n",
      "epoch 13, train loss: 1.2315\n",
      "validation loss 1.7028\n",
      "validation accuracy 0.5200\n",
      "epoch 14, train loss: 1.2096\n",
      "validation loss 1.7351\n",
      "validation accuracy 0.5142\n",
      "epoch 15, train loss: 1.1770\n",
      "validation loss 1.7412\n",
      "validation accuracy 0.5120\n",
      "epoch 16, train loss: 1.1597\n",
      "validation loss 1.7288\n",
      "validation accuracy 0.5212\n",
      "epoch 17, train loss: 1.1408\n",
      "validation loss 1.7306\n",
      "validation accuracy 0.5225\n",
      "epoch 18, train loss: 1.1299\n",
      "validation loss 1.7316\n",
      "validation accuracy 0.5240\n",
      "epoch 19, train loss: 1.1253\n",
      "validation loss 1.7264\n",
      "validation accuracy 0.5273\n"
     ]
    }
   ],
   "source": [
    "train(rnn2, epochs, dls_train, dls_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1421e5c",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "One problem with RNN is vanishing/exploding gradients. Since a sequence is very long, while updating our hidden layer, we multiply gradients by many times, this can make gradients very small/large. Instead of using a simple nn as a hidden layer, we use four nn, so instead of\n",
    "$$\n",
    "h_t = f(W h_{t-1} + U e_t + b)\n",
    "$$\n",
    "We use a LSTM cell that include four neural nets (orange boxes), as shown below.\n",
    "\n",
    "TODO: image\n",
    "\n",
    "The LSTM cell includes two hidden states instead of one in classic RNN. In classic RNN, the hidden state is responsible for:\n",
    "    1. Having the right information for the output layer to predict the correct next token\n",
    "    2. Retaining memory of everything that happened in the sentence\n",
    "It turns out that RNN is bad at memorizing things distant in the memory. So we introduces a **cell state** to keep track of the memory. The cell state is labeled $C$ in the figure. It is main responsible for keeping track of memory through selectively adding and forgetting things. The hidden state $h$ is responsible for sending things to the cell state thru nns and return output. \n",
    "\n",
    "The four neural nets are named: **forget gate** (sigmoid), **input gate** (sigmoid), **cell gate** (tanh) and **output gate** (sigmoid). For detailed walk thru of LSTM, see Colah's article linked below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c7b82",
   "metadata": {},
   "source": [
    "Now we create a literal translation based on the LSTM diagram above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ab1a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
    "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        h,c = state\n",
    "        h = torch.cat([h, input], dim=1)\n",
    "        forget = torch.sigmoid(self.forget_gate(h))\n",
    "        c = c * forget\n",
    "        inp = torch.sigmoid(self.input_gate(h))\n",
    "        cell = torch.tanh(self.cell_gate(h))\n",
    "        c = c + inp * cell\n",
    "        out = torch.sigmoid(self.output_gate(h))\n",
    "        h = out * torch.tanh(c)\n",
    "        return h, (h,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346d8a3",
   "metadata": {},
   "source": [
    "We recreate the model using pytorch's LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01517364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel5(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res,h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = [h_.detach() for h_ in h]\n",
    "        return self.h_o(res)\n",
    "    \n",
    "    def reset(self): \n",
    "        for h in self.h: h.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e72be1",
   "metadata": {},
   "source": [
    "We also train for 20 epochs. We also switched to AdamW optimizer for better performance since there are significantly more layers to train. As we can see, the accuracy is higher with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0ce1e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 3.3625\n",
      "validation loss 3.3053\n",
      "validation accuracy 0.1511\n",
      "epoch 1, train loss: 2.8902\n",
      "validation loss 2.7392\n",
      "validation accuracy 0.3241\n",
      "epoch 2, train loss: 2.2055\n",
      "validation loss 1.8999\n",
      "validation accuracy 0.4600\n",
      "epoch 3, train loss: 1.5229\n",
      "validation loss 1.8163\n",
      "validation accuracy 0.4513\n",
      "epoch 4, train loss: 1.3620\n",
      "validation loss 1.8125\n",
      "validation accuracy 0.4869\n",
      "epoch 5, train loss: 1.2466\n",
      "validation loss 2.0368\n",
      "validation accuracy 0.4884\n",
      "epoch 6, train loss: 1.1412\n",
      "validation loss 2.1412\n",
      "validation accuracy 0.5374\n",
      "epoch 7, train loss: 1.0477\n",
      "validation loss 2.1705\n",
      "validation accuracy 0.5298\n",
      "epoch 8, train loss: 0.9251\n",
      "validation loss 2.1211\n",
      "validation accuracy 0.5409\n",
      "epoch 9, train loss: 0.8050\n",
      "validation loss 1.8328\n",
      "validation accuracy 0.5688\n",
      "epoch 10, train loss: 0.6615\n",
      "validation loss 1.9828\n",
      "validation accuracy 0.5781\n",
      "epoch 11, train loss: 0.5230\n",
      "validation loss 1.8785\n",
      "validation accuracy 0.6050\n",
      "epoch 12, train loss: 0.4152\n",
      "validation loss 1.9530\n",
      "validation accuracy 0.6322\n",
      "epoch 13, train loss: 0.3382\n",
      "validation loss 1.9337\n",
      "validation accuracy 0.6369\n",
      "epoch 14, train loss: 0.2831\n",
      "validation loss 1.9904\n",
      "validation accuracy 0.6559\n",
      "epoch 15, train loss: 0.2449\n",
      "validation loss 1.9130\n",
      "validation accuracy 0.6693\n",
      "epoch 16, train loss: 0.2235\n",
      "validation loss 1.9406\n",
      "validation accuracy 0.6796\n",
      "epoch 17, train loss: 0.2107\n",
      "validation loss 1.9669\n",
      "validation accuracy 0.6746\n",
      "epoch 18, train loss: 0.2050\n",
      "validation loss 1.9519\n",
      "validation accuracy 0.6758\n",
      "epoch 19, train loss: 0.2033\n",
      "validation loss 1.9550\n",
      "validation accuracy 0.6753\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "rnn3 = LMModel5(len(vocab), 64, 2)\n",
    "optimizer = torch.optim.AdamW(rnn3.parameters(), lr=3e-3, weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=3e-3, steps_per_epoch=len(dls_train), epochs=epochs\n",
    ")\n",
    "\n",
    "train(rnn3, epochs, dls_train, dls_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e85d4f",
   "metadata": {},
   "source": [
    "# References:\n",
    "1. Colah, Understanding LSTM Networks: https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
